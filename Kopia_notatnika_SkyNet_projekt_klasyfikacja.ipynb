{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika SkyNet_projekt_klasyfikacja.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmfXxAtmtNu3B7k7hIucqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zedbog/First_repository/blob/master/Kopia_notatnika_SkyNet_projekt_klasyfikacja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msesZjCuEOXy"
      },
      "source": [
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import files\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA # służy do redukcji wymiarów\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRRQv4rfF2k9",
        "outputId": "f223ce46-09f2-476f-ff94-0fddd298812a"
      },
      "source": [
        "drive.mount(\"/content/drive\")\\"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFNYDZJ0moCW"
      },
      "source": [
        "#for i in range(4):\n",
        "  #files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLtB5aqGSBTZ"
      },
      "source": [
        "# Wczytanie danych\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/02_Projekt_praktyczny_klasyfikacja/df1.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/02_Projekt_praktyczny_klasyfikacja/df2.csv')\n",
        "attrition = pd.read_csv('/content/drive/MyDrive/02_Projekt_praktyczny_klasyfikacja/attrition.csv')\n",
        "sample = pd.read_csv('/content/drive/MyDrive/02_Projekt_praktyczny_klasyfikacja/sample_output.csv')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Nor5N2SkRr"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BBTo564Smhl"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_6bDcgvSoze"
      },
      "source": [
        "attrition.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLCrufnSqqA"
      },
      "source": [
        "sample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whA-h72zS4m8"
      },
      "source": [
        "#Sprawdzenie rozmiaru danych\n",
        "df1.shape , df2.shape, attrition.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eb1W2X0TEZ3"
      },
      "source": [
        "attrition.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6D0haAZTaAe",
        "outputId": "2c5022f2-f05b-40be-c0c2-56d6d5a7fbee"
      },
      "source": [
        "# Podział danych wyjściowych na treningowe i finalne testowe\n",
        "attrition_test = attrition[(attrition.Attrition == 'Yes') | (attrition.Attrition == 'No')]\n",
        "attrition_final_test = attrition[(attrition.Attrition != 'Yes') & (attrition.Attrition != 'No')]\n",
        "# Sprawdzenie rozmiaru podzielonych próbek\n",
        "attrition_test.shape, attrition_final_test.shape  "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4302, 2), (147, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IBWFJI2Sye6",
        "outputId": "5537d738-942c-4b74-f964-0303d15b9d88"
      },
      "source": [
        "# Zscalenie danych df1 i df2\n",
        "data = data = pd.concat([df1,df2],axis=1)\n",
        "# Sprawdzenie rozmiaru połączonych danych\n",
        "print(f'{data.shape}\\n')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4449, 37)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Hpb6Kj9LcqSl",
        "outputId": "cd662578-ed7b-437f-b0b0-a5e1ae5475a9"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Over18</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>YearlyIncome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>104</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>852.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>5126.0</td>\n",
              "      <td>15998.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>104</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>61512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1638</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>397.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Manufacturing Director</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>7756.0</td>\n",
              "      <td>14199.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1638</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>93072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>164</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>841.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>2368.0</td>\n",
              "      <td>23300.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>164</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>28416.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>395</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1117.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>66.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Single</td>\n",
              "      <td>3310.0</td>\n",
              "      <td>4488.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>395</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>39720.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53</td>\n",
              "      <td>35.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>464.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>1951.0</td>\n",
              "      <td>10910.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>53</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>23412.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EmployeeNumber   Age  ... Attrition  YearlyIncome\n",
              "0             104  30.0  ...        No       61512.0\n",
              "1            1638  38.0  ...        No       93072.0\n",
              "2             164  26.0  ...        No       28416.0\n",
              "3             395  28.0  ...        No       39720.0\n",
              "4              53  35.0  ...        No       23412.0\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISrR9mXqbIQN",
        "outputId": "f144652f-dcd9-4c9a-a995-49edade48805"
      },
      "source": [
        "# Usunięcie zduplikowanej kolumny w wyniku zscalenia\n",
        "data = data.loc[:,~data.columns.duplicated()]\n",
        "# Sprawdzenie rozmiaru połączonych danych\n",
        "print(f'{data.shape}')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4449, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "5FMmBno-TOlQ",
        "outputId": "8474ba11-8bbe-43bb-99d9-a9406014ad5f"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>Over18</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>YearlyIncome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4444</th>\n",
              "      <td>7975</td>\n",
              "      <td>8823.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>621.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Healthcare Representative</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>7978.0</td>\n",
              "      <td>14075.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>95736.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>7976</td>\n",
              "      <td>8823.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>621.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Healthcare Representative</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>7978.0</td>\n",
              "      <td>14075.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>95736.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4446</th>\n",
              "      <td>7977</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>381.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>918785.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Single</td>\n",
              "      <td>3708.0</td>\n",
              "      <td>2104.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>44496.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4447</th>\n",
              "      <td>7978</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>381.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>918785.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Single</td>\n",
              "      <td>3708.0</td>\n",
              "      <td>2104.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>44496.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4448</th>\n",
              "      <td>7979</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>381.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>918785.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Single</td>\n",
              "      <td>3708.0</td>\n",
              "      <td>2104.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>44496.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      EmployeeNumber     Age  ... Attrition  YearlyIncome\n",
              "4444            7975  8823.0  ...       Yes       95736.0\n",
              "4445            7976  8823.0  ...       Yes       95736.0\n",
              "4446            7977    44.0  ...       Yes       44496.0\n",
              "4447            7978    44.0  ...       Yes       44496.0\n",
              "4448            7979    44.0  ...       Yes       44496.0\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wtuyr2fi8c"
      },
      "source": [
        "# Usunięcie nic nie wnoszących danych\n",
        "data = data.drop(['EmployeeCount', 'StandardHours', 'YearlyIncome', 'Over18'], axis = 1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9pD6mdUeaft",
        "outputId": "8cd4f14d-b11a-4cfd-a111-47f59ac2ac69"
      },
      "source": [
        "# Podział danych wejściowych na treningowe i finalne testowe\n",
        "data_final_test = data[data.EmployeeNumber >= 10000]\n",
        "data_test = data[data.EmployeeNumber < 10000]\n",
        "# Sprawdzenie rozmiaru podzielonych próbek\n",
        "data_test.shape, data_final_test.shape  "
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4302, 32), (147, 32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzE57NMUhoZS"
      },
      "source": [
        "data_final_test.head() # Attrition w tym zbiorze to NaNy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVr-ym_xkSf9"
      },
      "source": [
        "# Zamiana atrybutu Attrition z 'Yes' na 1 i z 'No' na 0\n",
        "data_test.Attrition = data_test.Attrition.map({\"Yes\": 1, \"No\": 0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "vHsV-j7zfNWF",
        "outputId": "52e2f2f1-dbd4-46f9-d4d6-dfce9e4c93a6"
      },
      "source": [
        "data_test.describe()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "      <td>4302.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4809.243143</td>\n",
              "      <td>429.123199</td>\n",
              "      <td>800.843794</td>\n",
              "      <td>34478.313343</td>\n",
              "      <td>2.906788</td>\n",
              "      <td>2.719665</td>\n",
              "      <td>66.036495</td>\n",
              "      <td>2.741516</td>\n",
              "      <td>2.051604</td>\n",
              "      <td>2.722920</td>\n",
              "      <td>6453.266853</td>\n",
              "      <td>14266.381450</td>\n",
              "      <td>2.677359</td>\n",
              "      <td>15.164110</td>\n",
              "      <td>3.146444</td>\n",
              "      <td>2.725709</td>\n",
              "      <td>0.787773</td>\n",
              "      <td>354.004649</td>\n",
              "      <td>2.803347</td>\n",
              "      <td>2.765923</td>\n",
              "      <td>312.854719</td>\n",
              "      <td>367.109484</td>\n",
              "      <td>399.000930</td>\n",
              "      <td>334.767550</td>\n",
              "      <td>0.516504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2643.040205</td>\n",
              "      <td>1591.153416</td>\n",
              "      <td>405.655763</td>\n",
              "      <td>147682.315767</td>\n",
              "      <td>1.026460</td>\n",
              "      <td>1.092333</td>\n",
              "      <td>20.298352</td>\n",
              "      <td>0.711379</td>\n",
              "      <td>1.102569</td>\n",
              "      <td>1.106692</td>\n",
              "      <td>4672.993959</td>\n",
              "      <td>7154.584275</td>\n",
              "      <td>2.490632</td>\n",
              "      <td>3.624112</td>\n",
              "      <td>0.353591</td>\n",
              "      <td>1.079747</td>\n",
              "      <td>0.849147</td>\n",
              "      <td>1508.016854</td>\n",
              "      <td>1.302586</td>\n",
              "      <td>0.708878</td>\n",
              "      <td>1373.999529</td>\n",
              "      <td>1480.107024</td>\n",
              "      <td>1597.939659</td>\n",
              "      <td>1431.991884</td>\n",
              "      <td>0.499786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1009.000000</td>\n",
              "      <td>2094.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1680.250000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>457.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2897.000000</td>\n",
              "      <td>7910.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5828.500000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>804.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4876.000000</td>\n",
              "      <td>14174.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6903.750000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>1162.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8307.750000</td>\n",
              "      <td>20471.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7979.000000</td>\n",
              "      <td>9890.000000</td>\n",
              "      <td>1499.000000</td>\n",
              "      <td>999590.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>19999.000000</td>\n",
              "      <td>26999.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9939.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9984.000000</td>\n",
              "      <td>9937.000000</td>\n",
              "      <td>9990.000000</td>\n",
              "      <td>9882.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       EmployeeNumber          Age  ...  YearsWithCurrManager    Attrition\n",
              "count     4302.000000  4302.000000  ...           4302.000000  4302.000000\n",
              "mean      4809.243143   429.123199  ...            334.767550     0.516504\n",
              "std       2643.040205  1591.153416  ...           1431.991884     0.499786\n",
              "min          1.000000    18.000000  ...              0.000000     0.000000\n",
              "25%       1680.250000    31.000000  ...              2.000000     0.000000\n",
              "50%       5828.500000    36.000000  ...              3.000000     1.000000\n",
              "75%       6903.750000    45.000000  ...              7.000000     1.000000\n",
              "max       7979.000000  9890.000000  ...           9882.000000     1.000000\n",
              "\n",
              "[8 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "DldLp5wOfQnv",
        "outputId": "7a01d0bd-bf26-47c5-eb44-b3727d9a2caf"
      },
      "source": [
        "data_final_test.describe()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>147.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>100073.000000</td>\n",
              "      <td>37.619048</td>\n",
              "      <td>806.115646</td>\n",
              "      <td>9.761905</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.707483</td>\n",
              "      <td>64.238095</td>\n",
              "      <td>2.680272</td>\n",
              "      <td>2.108844</td>\n",
              "      <td>2.782313</td>\n",
              "      <td>6914.183673</td>\n",
              "      <td>14563.448980</td>\n",
              "      <td>2.809524</td>\n",
              "      <td>15.877551</td>\n",
              "      <td>3.210884</td>\n",
              "      <td>2.721088</td>\n",
              "      <td>0.727891</td>\n",
              "      <td>11.612245</td>\n",
              "      <td>2.972789</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>6.829932</td>\n",
              "      <td>4.414966</td>\n",
              "      <td>2.095238</td>\n",
              "      <td>4.129252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.579338</td>\n",
              "      <td>8.786145</td>\n",
              "      <td>405.476187</td>\n",
              "      <td>8.412591</td>\n",
              "      <td>0.986206</td>\n",
              "      <td>1.123905</td>\n",
              "      <td>19.640723</td>\n",
              "      <td>0.749305</td>\n",
              "      <td>1.117294</td>\n",
              "      <td>1.131837</td>\n",
              "      <td>4960.314224</td>\n",
              "      <td>7003.840122</td>\n",
              "      <td>2.385267</td>\n",
              "      <td>4.107957</td>\n",
              "      <td>0.409331</td>\n",
              "      <td>1.115165</td>\n",
              "      <td>0.815583</td>\n",
              "      <td>7.457137</td>\n",
              "      <td>1.399342</td>\n",
              "      <td>0.767490</td>\n",
              "      <td>5.414812</td>\n",
              "      <td>3.387818</td>\n",
              "      <td>2.977848</td>\n",
              "      <td>3.310987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1102.000000</td>\n",
              "      <td>2104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>100036.500000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>479.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>48.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3135.500000</td>\n",
              "      <td>8889.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>100073.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>773.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5154.000000</td>\n",
              "      <td>15146.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>100109.500000</td>\n",
              "      <td>43.500000</td>\n",
              "      <td>1163.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9625.000000</td>\n",
              "      <td>20470.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100146.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1499.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>19943.000000</td>\n",
              "      <td>26933.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       EmployeeNumber  ...  YearsWithCurrManager\n",
              "count      147.000000  ...            147.000000\n",
              "mean    100073.000000  ...              4.129252\n",
              "std         42.579338  ...              3.310987\n",
              "min     100000.000000  ...              0.000000\n",
              "25%     100036.500000  ...              2.000000\n",
              "50%     100073.000000  ...              3.000000\n",
              "75%     100109.500000  ...              7.000000\n",
              "max     100146.000000  ...             14.000000\n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "3H32UMfAf2Rn",
        "outputId": "a8e7a159-eda9-4f4d-bffb-86320a4b2b33"
      },
      "source": [
        "# Sprawdzenie korelacji między pozostałymi danymi\n",
        "sns.heatmap(data.corr())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5552c32438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx41mc0Pi-Vf",
        "outputId": "82cfaad5-e4c0-4eff-8de1-bec91d359675"
      },
      "source": [
        "# Porównanie średnich wartości w zbiorze final test i treningowym nieodfiltrowanym\n",
        "data_final_test.mean() , data_test.mean()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(EmployeeNumber              100073.000000\n",
              " Age                             37.619048\n",
              " DailyRate                      806.115646\n",
              " DistanceFromHome                 9.761905\n",
              " Education                        3.000000\n",
              " EnvironmentSatisfaction          2.707483\n",
              " HourlyRate                      64.238095\n",
              " JobInvolvement                   2.680272\n",
              " JobLevel                         2.108844\n",
              " JobSatisfaction                  2.782313\n",
              " MonthlyIncome                 6914.183673\n",
              " MonthlyRate                  14563.448980\n",
              " NumCompaniesWorked               2.809524\n",
              " PercentSalaryHike               15.877551\n",
              " PerformanceRating                3.210884\n",
              " RelationshipSatisfaction         2.721088\n",
              " StockOptionLevel                 0.727891\n",
              " TotalWorkingYears               11.612245\n",
              " TrainingTimesLastYear            2.972789\n",
              " WorkLifeBalance                  2.714286\n",
              " YearsAtCompany                   6.829932\n",
              " YearsInCurrentRole               4.414966\n",
              " YearsSinceLastPromotion          2.095238\n",
              " YearsWithCurrManager             4.129252\n",
              " Attrition                             NaN\n",
              " dtype: float64, EmployeeNumber               4809.243143\n",
              " Age                           429.123199\n",
              " DailyRate                     800.843794\n",
              " DistanceFromHome            34478.313343\n",
              " Education                       2.906788\n",
              " EnvironmentSatisfaction         2.719665\n",
              " HourlyRate                     66.036495\n",
              " JobInvolvement                  2.741516\n",
              " JobLevel                        2.051604\n",
              " JobSatisfaction                 2.722920\n",
              " MonthlyIncome                6453.266853\n",
              " MonthlyRate                 14266.381450\n",
              " NumCompaniesWorked              2.677359\n",
              " PercentSalaryHike              15.164110\n",
              " PerformanceRating               3.146444\n",
              " RelationshipSatisfaction        2.725709\n",
              " StockOptionLevel                0.787773\n",
              " TotalWorkingYears             354.004649\n",
              " TrainingTimesLastYear           2.803347\n",
              " WorkLifeBalance                 2.765923\n",
              " YearsAtCompany                312.854719\n",
              " YearsInCurrentRole            367.109484\n",
              " YearsSinceLastPromotion       399.000930\n",
              " YearsWithCurrManager          334.767550\n",
              " Attrition                       0.516504\n",
              " dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeG0RPFfjo_c"
      },
      "source": [
        "# Duże dysproporcje w średnich wystepują w następujących featurach:\n",
        "# Age, DistanceFromHome, TotalWorkinYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "GRAKwjiGeoyo",
        "outputId": "699b1315-ade5-4171-9d46-e59118977eab"
      },
      "source": [
        "# Odsianie wartości skrajnych\n",
        "Q1 = data_test.quantile(0.00)\n",
        "Q3 = data_test.quantile(0.93)\n",
        "IQR = Q3 - Q1\n",
        "data_test_filtered = data_test[~((data_test < (Q1 - 1.5 * IQR)) | (data_test > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "data_test_filtered.describe()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "      <td>2351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3399.864313</td>\n",
              "      <td>36.967248</td>\n",
              "      <td>799.252233</td>\n",
              "      <td>9.253509</td>\n",
              "      <td>2.915355</td>\n",
              "      <td>2.713313</td>\n",
              "      <td>66.503615</td>\n",
              "      <td>2.751595</td>\n",
              "      <td>2.073586</td>\n",
              "      <td>2.720119</td>\n",
              "      <td>6541.506168</td>\n",
              "      <td>14289.114845</td>\n",
              "      <td>2.673330</td>\n",
              "      <td>15.146321</td>\n",
              "      <td>3.145045</td>\n",
              "      <td>2.759677</td>\n",
              "      <td>0.769885</td>\n",
              "      <td>11.349213</td>\n",
              "      <td>2.765632</td>\n",
              "      <td>2.777116</td>\n",
              "      <td>7.143769</td>\n",
              "      <td>4.238622</td>\n",
              "      <td>2.149298</td>\n",
              "      <td>4.222884</td>\n",
              "      <td>0.384517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2787.632321</td>\n",
              "      <td>9.108810</td>\n",
              "      <td>400.960014</td>\n",
              "      <td>8.137460</td>\n",
              "      <td>1.026491</td>\n",
              "      <td>1.083488</td>\n",
              "      <td>20.121564</td>\n",
              "      <td>0.701042</td>\n",
              "      <td>1.106320</td>\n",
              "      <td>1.092691</td>\n",
              "      <td>4727.405739</td>\n",
              "      <td>7052.760571</td>\n",
              "      <td>2.507615</td>\n",
              "      <td>3.578521</td>\n",
              "      <td>0.352221</td>\n",
              "      <td>1.077273</td>\n",
              "      <td>0.828869</td>\n",
              "      <td>7.872394</td>\n",
              "      <td>1.313411</td>\n",
              "      <td>0.707771</td>\n",
              "      <td>6.293915</td>\n",
              "      <td>3.644356</td>\n",
              "      <td>3.212648</td>\n",
              "      <td>3.650894</td>\n",
              "      <td>0.486584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1009.000000</td>\n",
              "      <td>2094.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>909.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>461.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2932.000000</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1830.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>802.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4968.000000</td>\n",
              "      <td>14199.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6226.500000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>1153.500000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8487.000000</td>\n",
              "      <td>20351.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7963.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1498.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>19999.000000</td>\n",
              "      <td>26999.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       EmployeeNumber          Age  ...  YearsWithCurrManager    Attrition\n",
              "count     2351.000000  2351.000000  ...           2351.000000  2351.000000\n",
              "mean      3399.864313    36.967248  ...              4.222884     0.384517\n",
              "std       2787.632321     9.108810  ...              3.650894     0.486584\n",
              "min          1.000000    18.000000  ...              0.000000     0.000000\n",
              "25%        909.500000    30.000000  ...              2.000000     0.000000\n",
              "50%       1830.000000    36.000000  ...              3.000000     0.000000\n",
              "75%       6226.500000    43.000000  ...              7.000000     1.000000\n",
              "max       7963.000000    60.000000  ...             17.000000     1.000000\n",
              "\n",
              "[8 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh7BcLMhhTpQ",
        "outputId": "2cd5f6d5-285b-4eee-be0d-084a14095111"
      },
      "source": [
        "# Porównanie średnich wartości w zbiorze final test i treningowym odfiltrowanym\n",
        "data_final_test.mean() , data_test_filtered.mean()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(EmployeeNumber              100073.000000\n",
              " Age                             37.619048\n",
              " DailyRate                      806.115646\n",
              " DistanceFromHome                 9.761905\n",
              " Education                        3.000000\n",
              " EnvironmentSatisfaction          2.707483\n",
              " HourlyRate                      64.238095\n",
              " JobInvolvement                   2.680272\n",
              " JobLevel                         2.108844\n",
              " JobSatisfaction                  2.782313\n",
              " MonthlyIncome                 6914.183673\n",
              " MonthlyRate                  14563.448980\n",
              " NumCompaniesWorked               2.809524\n",
              " PercentSalaryHike               15.877551\n",
              " PerformanceRating                3.210884\n",
              " RelationshipSatisfaction         2.721088\n",
              " StockOptionLevel                 0.727891\n",
              " TotalWorkingYears               11.612245\n",
              " TrainingTimesLastYear            2.972789\n",
              " WorkLifeBalance                  2.714286\n",
              " YearsAtCompany                   6.829932\n",
              " YearsInCurrentRole               4.414966\n",
              " YearsSinceLastPromotion          2.095238\n",
              " YearsWithCurrManager             4.129252\n",
              " Attrition                             NaN\n",
              " dtype: float64, EmployeeNumber               3399.864313\n",
              " Age                            36.967248\n",
              " DailyRate                     799.252233\n",
              " DistanceFromHome                9.253509\n",
              " Education                       2.915355\n",
              " EnvironmentSatisfaction         2.713313\n",
              " HourlyRate                     66.503615\n",
              " JobInvolvement                  2.751595\n",
              " JobLevel                        2.073586\n",
              " JobSatisfaction                 2.720119\n",
              " MonthlyIncome                6541.506168\n",
              " MonthlyRate                 14289.114845\n",
              " NumCompaniesWorked              2.673330\n",
              " PercentSalaryHike              15.146321\n",
              " PerformanceRating               3.145045\n",
              " RelationshipSatisfaction        2.759677\n",
              " StockOptionLevel                0.769885\n",
              " TotalWorkingYears              11.349213\n",
              " TrainingTimesLastYear           2.765632\n",
              " WorkLifeBalance                 2.777116\n",
              " YearsAtCompany                  7.143769\n",
              " YearsInCurrentRole              4.238622\n",
              " YearsSinceLastPromotion         2.149298\n",
              " YearsWithCurrManager            4.222884\n",
              " Attrition                       0.384517\n",
              " dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP2yaEgKe5KH"
      },
      "source": [
        "Z zestawienia wartości średnich zbioru testowego i treningowego widać, że po odsianiu górnych 7% wartości rząd wielkości wartości średnich w obu zbiorach danych jest zbliżony.\n",
        "Pozwala wysnuć to wniosek, że dane wykorzystane do wyuczenia modelu dadzą wiarygodne wyniki dla danych testowych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u28kyyLdd5n6"
      },
      "source": [
        "data_test_filtered_without_empnum_atr = data_test_filtered.drop(labels=['EmployeeNumber', 'Attrition'], axis=1)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUtvpwqufQnw",
        "outputId": "63f79b6c-1aa7-40fd-bff2-8a4763e1eedd"
      },
      "source": [
        "data_test_filtered_without_empnum_atr.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2351, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhTlZAoJdiVn",
        "outputId": "d515548c-c2b9-4090-ed76-4a8325884276"
      },
      "source": [
        "# Sprawdzenie czy odfiltrowane dane posiadają duplikaty\n",
        "data_test_filtered_without_empnum_atr.duplicated().sum()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7IlZ1VPeg19"
      },
      "source": [
        "# Usunięcie duplikatów\n",
        "data_test_filtered_unduplicated = data_test_filtered_without_empnum_atr.drop_duplicates(keep=False)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znNYO69jfbub",
        "outputId": "96be744d-e5fe-4a4c-b12e-65d0de57dfb4"
      },
      "source": [
        "# Sprawdzenie rozmiaru danych po usunięciu duplikatów\n",
        "data_test_filtered_unduplicated.shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(875, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdO3eq69fy_4",
        "outputId": "084cd267-b453-4f71-8241-df501de21181"
      },
      "source": [
        "# Weryfikacja duplikatów\n",
        "data_test_filtered_unduplicated.duplicated().sum()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KoVtkyOj9yu"
      },
      "source": [
        "# Przywrócenie kolumny Attrition i EmployeeNumber w przygotowanych danych\n",
        "data_test_filtered_unduplicated_with_attr = data_test_filtered_unduplicated.merge(data_test_filtered, how='left')"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PRE19yeqkc3",
        "outputId": "c899aa43-c4bc-450f-9bbb-f37a36b36cf8"
      },
      "source": [
        "# Sprawdzenie rozmiaru danych\n",
        "data_test_filtered_unduplicated_with_attr.shape"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(875, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "gSrSaRNbqr8y",
        "outputId": "81911d5b-bc52-4b52-d3ab-fa68ebc7f8ff"
      },
      "source": [
        "data_test_filtered_unduplicated_with_attr.head()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>852.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>5126.0</td>\n",
              "      <td>15998.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>397.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Manufacturing Director</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>7756.0</td>\n",
              "      <td>14199.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1638</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>841.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>2368.0</td>\n",
              "      <td>23300.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>464.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>1951.0</td>\n",
              "      <td>10910.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>Human Resources</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Technical Degree</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Human Resources</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>2742.0</td>\n",
              "      <td>3072.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1467</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age BusinessTravel  ...  EmployeeNumber Attrition\n",
              "0  30.0  Travel_Rarely  ...             104         0\n",
              "1  38.0  Travel_Rarely  ...            1638         0\n",
              "2  26.0  Travel_Rarely  ...             164         0\n",
              "3  35.0  Travel_Rarely  ...              53         0\n",
              "4  34.0  Travel_Rarely  ...            1467         1\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cycrluTgKll"
      },
      "source": [
        "Dane zostały odfiltorwane i zostały usunięte duplikaty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yircfOE9f8Eu"
      },
      "source": [
        "# Zamiana w etykietowwanych featurach etykiet klasyfikujących na one hot vector\n",
        "data_test_filtered_dummies = pd.get_dummies(data_test_filtered_unduplicated_with_attr, columns=['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime'])"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LHwulJJjCRZ",
        "outputId": "a1e7ae16-7f1e-4b38-bb03-09edd907cc10"
      },
      "source": [
        "# Sprawdzenie rozmiaru one hot vector\n",
        "data_test_filtered_dummies.shape"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(875, 53)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "62MErPSzjQ0G",
        "outputId": "402545d9-208a-49ef-9a60-86258400381f"
      },
      "source": [
        "data_test_filtered_dummies.head()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>852.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5126.0</td>\n",
              "      <td>15998.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7756.0</td>\n",
              "      <td>14199.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1638</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>841.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2368.0</td>\n",
              "      <td>23300.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1951.0</td>\n",
              "      <td>10910.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.0</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2742.0</td>\n",
              "      <td>3072.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1467</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  DailyRate  ...  OverTime_No  OverTime_Yes\n",
              "0  30.0      852.0  ...            0             1\n",
              "1  38.0      397.0  ...            0             1\n",
              "2  26.0      841.0  ...            1             0\n",
              "3  35.0      464.0  ...            1             0\n",
              "4  34.0     1107.0  ...            1             0\n",
              "\n",
              "[5 rows x 53 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlNgRsjrrvYN"
      },
      "source": [
        "# Pozbycie się EmployeeNumber\n",
        "data_test_filtered_dummies_without_empnum = data_test_filtered_dummies.drop(labels=['EmployeeNumber'], axis=1)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-wQPoOsz9p",
        "outputId": "0c2a1e48-35a0-4f89-8f3d-46c7b5beb5e6"
      },
      "source": [
        "# Sprawdzenie ilości pustych rekordów\n",
        "data_test_filtered_dummies_without_empnum.isnull().sum().sum()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "o6XKy56Ve338",
        "outputId": "bf4cc026-c714-4c30-ff16-abfd02429860"
      },
      "source": [
        "# Redukcja wymiarowości i sprawdzenie rozkładu danych \n",
        "plt.figure(figsize=(10, 5))\n",
        "X_pca = PCA().fit_transform(data_test_filtered_dummies_without_empnum.loc[:, data_test_filtered_dummies_without_empnum.columns != 'Attrition'])\n",
        "plt.title('PCA dataset')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2 ')\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], c=data_test_filtered_dummies_without_empnum.Attrition)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f554e36bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infW_fImlKCV"
      },
      "source": [
        "Przyjmujemy, że powyższy rozkład danych może zostać przyjęty do rozważania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfhjgw0mEgb",
        "outputId": "c949a5b0-41c2-44af-91e3-75a8c4b19778"
      },
      "source": [
        "# Sprawdzenie rozkładu klas po odfiltorwaniu danych\n",
        "data_test_filtered_dummies_without_empnum.Attrition.value_counts()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    721\n",
              "1    154\n",
              "Name: Attrition, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqg88-HImMc_"
      },
      "source": [
        "W związku z niezbalansowanym rozkładem członków poszczególnych klas w odfiltrowanym zbiorze danych dokonujemy OVERSAMPLINGU w celu zrównania obu populacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHFcHcXOmaqp",
        "outputId": "4335661d-7dff-4db0-863d-472337bf653e"
      },
      "source": [
        "attrition_no = data_test_filtered_dummies_without_empnum[data_test_filtered_dummies_without_empnum.Attrition == 0]\n",
        "attrition_yes = data_test_filtered_dummies_without_empnum[data_test_filtered_dummies_without_empnum.Attrition == 1]\n",
        "\n",
        "# Upsample attrition_yes class\n",
        "attrition_yes_upsampled = resample(attrition_yes,\n",
        "                            replace=True,    # sample with replacement\n",
        "                            n_samples=len(attrition_no),    # to match majority class\n",
        "                            random_state=42) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "data_test_filtered_dummies_upsampled = pd.concat([attrition_no, attrition_yes_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "data_test_filtered_dummies_upsampled.Attrition.value_counts()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    721\n",
              "0    721\n",
              "Name: Attrition, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBeJk-4QtTUh",
        "outputId": "596556ae-3343-4dd3-eb97-f7454dc25485"
      },
      "source": [
        "# Sprawdzamy ilość powstałych duplikatów\n",
        "data_test_filtered_dummies_upsampled.duplicated().sum()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkuogkVPvb-K"
      },
      "source": [
        "W związku z tym, że najpeirw usuwaliśmy duplikaty z różnymi wartosciami Attrition, a następnie robimy OVERSAMPLING, w wyniku którego znowu generujemy duplikaty (tym razem jednak wiarygodne) to warto rozważyć także UNDERSAMPLING."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygYdhmrPv1d4",
        "outputId": "a6cdde35-2b6d-4b5f-e556-7a73bb930a97"
      },
      "source": [
        "attrition_no = data_test_filtered_dummies_without_empnum[data_test_filtered_dummies_without_empnum.Attrition == 0]\n",
        "attrition_yes = data_test_filtered_dummies_without_empnum[data_test_filtered_dummies_without_empnum.Attrition == 1]\n",
        "\n",
        "# Upsample attrition_yes class\n",
        "attrition_no_undersampled = resample(attrition_no,\n",
        "                            replace=False,    # sample with replacement\n",
        "                            n_samples=len(attrition_yes),    # to match majority class\n",
        "                            random_state=42) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "data_test_filtered_dummies_undersampled = pd.concat([attrition_no_undersampled, attrition_yes])\n",
        " \n",
        "# Display new class counts\n",
        "data_test_filtered_dummies_undersampled.Attrition.value_counts()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    154\n",
              "0    154\n",
              "Name: Attrition, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S55OoeEhlQxH"
      },
      "source": [
        "# Przypisanie zmiennych do X i y\n",
        "X = data_test_filtered_dummies_without_empnum.loc[:, data_test_filtered_dummies_without_empnum.columns != 'Attrition']\n",
        "y = data_test_filtered_dummies_without_empnum.Attrition\n",
        "\n",
        "# Przypisanie zmiennych do X_upsampled i y_upsampled\n",
        "X_upsampled = data_test_filtered_dummies_upsampled.loc[:, data_test_filtered_dummies_upsampled.columns != 'Attrition']\n",
        "y_upsampled = data_test_filtered_dummies_upsampled.Attrition\n",
        "\n",
        "# Przypisanie zmiennych do X_undersampled i y_undersampled\n",
        "X_undersampled = data_test_filtered_dummies_undersampled.loc[:, data_test_filtered_dummies_undersampled.columns != 'Attrition']\n",
        "y_undersampled = data_test_filtered_dummies_undersampled.Attrition"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "iAP3wKxel2sA",
        "outputId": "d4f9e16b-a69a-4acb-95c4-7464d3acf8a8"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>852.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5126.0</td>\n",
              "      <td>15998.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7756.0</td>\n",
              "      <td>14199.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>841.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2368.0</td>\n",
              "      <td>23300.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0</td>\n",
              "      <td>464.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1951.0</td>\n",
              "      <td>10910.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.0</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2742.0</td>\n",
              "      <td>3072.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  DailyRate  ...  OverTime_No  OverTime_Yes\n",
              "0  30.0      852.0  ...            0             1\n",
              "1  38.0      397.0  ...            0             1\n",
              "2  26.0      841.0  ...            1             0\n",
              "3  35.0      464.0  ...            1             0\n",
              "4  34.0     1107.0  ...            1             0\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93i0uckXl3-m",
        "outputId": "0ddcafed-e7f3-4a6f-b618-c27ec616402e"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    1\n",
              "Name: Attrition, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alyr-0Qlo_vJ"
      },
      "source": [
        "Trenowanie modeli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GmCgWgfpRNo"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42, stratify=y_upsampled)\n",
        "X_train_undersampled, X_test_undersampled, y_train_undersampled, y_test_undersampled = train_test_split(X_undersampled, y_undersampled, test_size=0.2, random_state=42, stratify=y_undersampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISFUlD5SpE_c"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIMlsww-za0C"
      },
      "source": [
        "params_lr = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'solver': ['newton-cg','saga', 'liblinear', 'lbfgs'],\n",
        "    'max_iter': [100, 500, 1000, 5000]\n",
        "}"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbfg94XRpC2m"
      },
      "source": [
        "clf = GridSearchCV(LogisticRegression(), params_lr, scoring='f1')\n",
        "clf.fit(X_train, y_train)\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPQL-jEao4JH",
        "outputId": "6c5c4c64-c23c-4b18-a7b5-b94a84decb33"
      },
      "source": [
        "model = LogisticRegression(C=1000, max_iter=500, solver='newton-cg')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_lr = model.predict(X_test)\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_lr)}\\nAverage F1 score: {f1_score(y_test, y_pred_lr, average=\"micro\")}')"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91       144\n",
            "           1       0.67      0.19      0.30        31\n",
            "\n",
            "    accuracy                           0.84       175\n",
            "   macro avg       0.76      0.59      0.60       175\n",
            "weighted avg       0.82      0.84      0.80       175\n",
            "\n",
            "Average F1 score: 0.8399999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJbbrEFFzWLa"
      },
      "source": [
        "clf = GridSearchCV(LogisticRegression(), params_lr, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_EwZhV708ur",
        "outputId": "b08bcb33-3e59-4367-c0bb-54d4d67e4704"
      },
      "source": [
        "model = LogisticRegression(C=100, max_iter=100, solver='newton-cg')\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_lr_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED\\n{classification_report(y_test_upsampled, y_pred_lr_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_lr_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression UPSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79       145\n",
            "           1       0.80      0.76      0.78       144\n",
            "\n",
            "    accuracy                           0.78       289\n",
            "   macro avg       0.78      0.78      0.78       289\n",
            "weighted avg       0.78      0.78      0.78       289\n",
            "\n",
            "Average F1 score: 0.7820069204152249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwuBMCCLziGk",
        "outputId": "4eb0983d-2243-4223-98f6-0e24238a770b"
      },
      "source": [
        "clf = GridSearchCV(LogisticRegression(), params_lr, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1000, 'max_iter': 100, 'solver': 'newton-cg'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWJpq1sf13ef",
        "outputId": "1a341762-7829-4d83-90d7-df316a108e29"
      },
      "source": [
        "model = LogisticRegression(C=1000, max_iter=100, solver='newton-cg')\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_lr_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_lr_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_lr_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.68      0.67        31\n",
            "           1       0.67      0.65      0.66        31\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.66      0.66      0.66        62\n",
            "weighted avg       0.66      0.66      0.66        62\n",
            "\n",
            "Average F1 score: 0.6612903225806451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfi3cDKu0Ng"
      },
      "source": [
        "#KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8VTXfW3eVo"
      },
      "source": [
        "params_knn= {\n",
        "    'n_neighbors': [2, 3, 5, 7, 10, 15],\n",
        "    'algorithm': ['auto','ball_tree', 'kd_tree'],\n",
        "    'p': [1, 2]\n",
        "}"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0DkSkhRuzw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2558cc-fb19-4f5a-d7b2-7cb88548da00"
      },
      "source": [
        "clf = GridSearchCV(KNeighborsClassifier(), params_knn, scoring='f1')\n",
        "clf.fit(X_train, y_train)\n",
        "clf.best_params_"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'auto', 'n_neighbors': 5, 'p': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFVxWt6YvBqP",
        "outputId": "82c0024c-9127-4ad0-a933-603ed6c01a97"
      },
      "source": [
        "model = KNeighborsClassifier(algorithm='auto', n_neighbors=5, p=2)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_knn = model.predict(X_test)\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_knn)}\\nAverage F1 score: {f1_score(y_test, y_pred_knn, average=\"micro\")}')"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88       144\n",
            "           1       0.12      0.03      0.05        31\n",
            "\n",
            "    accuracy                           0.79       175\n",
            "   macro avg       0.47      0.49      0.47       175\n",
            "weighted avg       0.70      0.79      0.73       175\n",
            "\n",
            "Average F1 score: 0.7885714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z-pIQmi3oQS",
        "outputId": "1ca55a19-0f20-4add-9858-3963966f5e7e"
      },
      "source": [
        "clf = GridSearchCV(KNeighborsClassifier(), params_knn, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'auto', 'n_neighbors': 2, 'p': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT7ZVL8R3uQs",
        "outputId": "4e34aba2-cc33-432b-fd37-8edc1968f382"
      },
      "source": [
        "model = KNeighborsClassifier(algorithm='auto', n_neighbors=2, p=1)\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_knn_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_knn_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_knn_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       145\n",
            "           1       0.89      0.91      0.90       144\n",
            "\n",
            "    accuracy                           0.90       289\n",
            "   macro avg       0.90      0.90      0.90       289\n",
            "weighted avg       0.90      0.90      0.90       289\n",
            "\n",
            "Average F1 score: 0.8996539792387543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUMTvSho4CWI",
        "outputId": "6c8bb950-c1b6-46c9-ea68-6f9cce6cd3b4"
      },
      "source": [
        "clf = GridSearchCV(KNeighborsClassifier(), params_knn, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'auto', 'n_neighbors': 15, 'p': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6UNtLw94IgE",
        "outputId": "8a89ab55-3334-4649-9522-0c7874fb6407"
      },
      "source": [
        "model = KNeighborsClassifier(algorithm='auto', n_neighbors=15, p=2)\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_knn_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_knn_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_knn_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61        31\n",
            "           1       0.62      0.68      0.65        31\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.63      0.63      0.63        62\n",
            "weighted avg       0.63      0.63      0.63        62\n",
            "\n",
            "Average F1 score: 0.6290322580645161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSPVY9w9FKPx"
      },
      "source": [
        "#SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RUE6Ip-4vgH"
      },
      "source": [
        "params_svc= {\n",
        "    'C': [1, 10, 100],\n",
        "    # 'kernel': ['linear'],\n",
        "    'gamma':[0.000001, 0.0001, 0.001, 1],\n",
        "   'class_weight': [None, 'balanced']\n",
        "}  "
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7H-nIF7ueDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ae4a23-978d-4399-f7de-7dac31249018"
      },
      "source": [
        "clf = GridSearchCV(SVC(), params_svc, scoring='f1')\n",
        "clf.fit(X_train, y_train)\n",
        "clf.best_params_"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'class_weight': 'balanced', 'gamma': 1e-06}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8To4jgE1TPD",
        "outputId": "17c3b503-9ca5-4811-e6e1-556346ea432e"
      },
      "source": [
        "model = SVC(C=1, class_weight='balanced', gamma=0.000001)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_svc = model.predict(X_test)\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_svc)}\\nAverage F1 score: {f1_score(y_test, y_pred_svc, average=\"micro\")}')"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       144\n",
            "           1       0.25      0.45      0.32        31\n",
            "\n",
            "    accuracy                           0.66       175\n",
            "   macro avg       0.55      0.58      0.55       175\n",
            "weighted avg       0.75      0.66      0.70       175\n",
            "\n",
            "Average F1 score: 0.6628571428571428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZOfXbhE5IsC",
        "outputId": "6076c1d0-564c-4be7-83e7-8dc1f075664f"
      },
      "source": [
        "clf = GridSearchCV(SVC(), params_svc, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'class_weight': None, 'gamma': 0.0001}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2u2stX95Rg_",
        "outputId": "6ee6c57f-fb9b-4daf-8ee0-75eaa05c978c"
      },
      "source": [
        "model = SVC(C=1, class_weight=None, gamma=0.0001)\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_svc_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED\\n{classification_report(y_test_upsampled, y_pred_svc_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_svc_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC UPSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       145\n",
            "           1       1.00      0.98      0.99       144\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.99      0.99      0.99       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "Average F1 score: 0.9896193771626297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZ8J06s5pNV",
        "outputId": "14500dea-82f8-4cfc-c636-122e9e2899dc"
      },
      "source": [
        "clf = GridSearchCV(SVC(), params_svc, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'class_weight': None, 'gamma': 1e-06}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dFzMjp65xsB",
        "outputId": "5ba3b4d2-249d-43b2-f414-483384caba5c"
      },
      "source": [
        "model = SVC(C=1, class_weight=None, gamma=0.000001)\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_svc_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED\\n{classification_report(y_test_undersampled, y_pred_svc_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_svc_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC UNDERSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.84      0.74        31\n",
            "           1       0.78      0.58      0.67        31\n",
            "\n",
            "    accuracy                           0.71        62\n",
            "   macro avg       0.72      0.71      0.70        62\n",
            "weighted avg       0.72      0.71      0.70        62\n",
            "\n",
            "Average F1 score: 0.7096774193548389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZn-pINh8a39"
      },
      "source": [
        "Weryfikacja zachowania modelu SVC na zbiorze treningowym, walidacyjnym i testowym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nDXSHNY6dLA"
      },
      "source": [
        "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=10, stratify=y_upsampled)\n",
        "X_train_upsampled_val, X_test_upsampled_val, y_train_upsampled_val, y_test_upsampled_val = train_test_split(X_train_upsampled, y_train_upsampled, test_size=0.25, random_state=10, stratify=y_train_upsampled)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clUxAQAq7LLq",
        "outputId": "2e2dc1db-82a9-4f5e-e4d6-209115461220"
      },
      "source": [
        "X_train_upsampled_val.shape, X_test_upsampled_val.shape, y_train_upsampled_val.shape, y_test_upsampled_val.shape"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((864, 51), (289, 51), (864,), (289,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vihqwRKZ7Aet",
        "outputId": "f1fba3e9-1b2c-4de2-e6b9-3b435e098c22"
      },
      "source": [
        "model = SVC(C=1, class_weight=None, gamma=0.0001)\n",
        "model.fit(X_train_upsampled_val, y_train_upsampled_val)\n",
        "y_pred_svc_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED\\n{classification_report(y_test_upsampled, y_pred_svc_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_svc_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC UPSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       144\n",
            "           1       1.00      0.94      0.97       145\n",
            "\n",
            "    accuracy                           0.97       289\n",
            "   macro avg       0.97      0.97      0.97       289\n",
            "weighted avg       0.97      0.97      0.97       289\n",
            "\n",
            "Average F1 score: 0.9688581314878892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PObFaq758jQG"
      },
      "source": [
        "# Przypisanie poprzedniej wartości X_upsampled, y_upsampled\n",
        "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42, stratify=y_upsampled)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgrGvq369nJt",
        "outputId": "97b4f5a1-f318-4ed9-fbe3-39060a072ac7"
      },
      "source": [
        "model = SVC(C=1, class_weight=None, gamma=0.0001)\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_svc_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED\\n{classification_report(y_test_upsampled, y_pred_svc_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_svc_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC UPSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       145\n",
            "           1       1.00      0.98      0.99       144\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.99      0.99      0.99       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "Average F1 score: 0.9896193771626297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duT_B5oGvS_f"
      },
      "source": [
        "#DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_gKbiQF8tDD"
      },
      "source": [
        "params_tree = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, 9, 12, 15],\n",
        "    'min_samples_split': [2, 4, 7],\n",
        "    'min_samples_leaf': [1, 3, 5]\n",
        "}"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZXp029jvSiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a497c3ee-25c3-4543-97e6-ca4f026ebbad"
      },
      "source": [
        "clf = GridSearchCV(DecisionTreeClassifier(), params_tree, scoring='f1')\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "clf.best_params_"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 7,\n",
              " 'min_samples_leaf': 5,\n",
              " 'min_samples_split': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVam55leuYxw",
        "outputId": "d8c9fb0c-b18d-4278-e289-040c9d21ba86"
      },
      "source": [
        "model = DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_leaf=5, min_samples_split=7)\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_tree = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_tree)}\\nAverage F1 score: {f1_score(y_test, y_pred_tree, average=\"micro\")}')"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       144\n",
            "           1       0.45      0.29      0.35        31\n",
            "\n",
            "    accuracy                           0.81       175\n",
            "   macro avg       0.65      0.61      0.62       175\n",
            "weighted avg       0.79      0.81      0.79       175\n",
            "\n",
            "Average F1 score: 0.8114285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX_4PAmE808g",
        "outputId": "32c983d3-666f-41b5-95d3-fe6fd377b3b5"
      },
      "source": [
        "clf = GridSearchCV(DecisionTreeClassifier(), params_tree, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qstMP4n86Vm",
        "outputId": "e7c5e94b-be63-4970-800e-e02c75d02d28"
      },
      "source": [
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=1, min_samples_split=4)\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_tree_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_tree_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_tree_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92       145\n",
            "           1       0.88      0.99      0.93       144\n",
            "\n",
            "    accuracy                           0.93       289\n",
            "   macro avg       0.93      0.93      0.93       289\n",
            "weighted avg       0.93      0.93      0.93       289\n",
            "\n",
            "Average F1 score: 0.9273356401384083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ITcPiUD9Scs",
        "outputId": "f6d09c18-a958-4555-846b-1d124771fa9e"
      },
      "source": [
        "clf = GridSearchCV(DecisionTreeClassifier(), params_tree, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 9,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmneYX-A9YRU",
        "outputId": "55fc1d1c-1575-4569-9ef9-501434c65401"
      },
      "source": [
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=1, min_samples_split=2)\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_tree_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERAMPLED \\n{classification_report(y_test_undersampled, y_pred_tree_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_tree_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier UNDERAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62        31\n",
            "           1       0.62      0.65      0.63        31\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.63      0.63      0.63        62\n",
            "weighted avg       0.63      0.63      0.63        62\n",
            "\n",
            "Average F1 score: 0.6290322580645161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zdD1_RGwaou"
      },
      "source": [
        "#GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6N5nYoWvwwN",
        "outputId": "63060e56-2179-49a9-f56b-209dc52c6a8f"
      },
      "source": [
        "model = GaussianNB()\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_gnb = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_gnb)}\\nAverage F1 score: {f1_score(y_test, y_pred_gnb, average=\"micro\")}')"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84       144\n",
            "           1       0.40      0.74      0.52        31\n",
            "\n",
            "    accuracy                           0.75       175\n",
            "   macro avg       0.66      0.75      0.68       175\n",
            "weighted avg       0.84      0.75      0.78       175\n",
            "\n",
            "Average F1 score: 0.7542857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRWdLbD69wp0",
        "outputId": "84ae864d-3b4d-4875-bdad-fbbd235b39d0"
      },
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_gnb_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_gnb_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_gnb_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.61      0.65       145\n",
            "           1       0.65      0.74      0.69       144\n",
            "\n",
            "    accuracy                           0.67       289\n",
            "   macro avg       0.67      0.67      0.67       289\n",
            "weighted avg       0.67      0.67      0.67       289\n",
            "\n",
            "Average F1 score: 0.671280276816609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiCeX0Jf-FAD",
        "outputId": "0caef368-fbb3-4fb3-c511-b002695757c6"
      },
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_gnb_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_gnb_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_gnb_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.48      0.58        31\n",
            "           1       0.61      0.81      0.69        31\n",
            "\n",
            "    accuracy                           0.65        62\n",
            "   macro avg       0.66      0.65      0.64        62\n",
            "weighted avg       0.66      0.65      0.64        62\n",
            "\n",
            "Average F1 score: 0.6451612903225806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4R61i1lwllk"
      },
      "source": [
        "#MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YZnVJOKwqxK",
        "outputId": "5c86ce47-7ad0-4a2b-a2bd-2fe4a7b28456"
      },
      "source": [
        "model = MultinomialNB()\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_mnb = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_mnb)}\\nAverage F1 score: {f1_score(y_test, y_pred_mnb, average=\"micro\")}')"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.53      0.66       144\n",
            "           1       0.20      0.55      0.30        31\n",
            "\n",
            "    accuracy                           0.54       175\n",
            "   macro avg       0.52      0.54      0.48       175\n",
            "weighted avg       0.73      0.54      0.59       175\n",
            "\n",
            "Average F1 score: 0.5371428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZzMXjjZ-bgJ",
        "outputId": "bdc59a62-581f-4345-e93c-3c523c59c983"
      },
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_mnb_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_gnb_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_gnb_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53       145\n",
            "           1       0.53      0.53      0.53       144\n",
            "\n",
            "    accuracy                           0.53       289\n",
            "   macro avg       0.53      0.53      0.53       289\n",
            "weighted avg       0.53      0.53      0.53       289\n",
            "\n",
            "Average F1 score: 0.5294117647058824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9xF82An-iN_",
        "outputId": "28e466fc-581c-4dd4-aff9-dde8546cd669"
      },
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_mnb_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_gnb_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_gnb_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.48      0.55        31\n",
            "           1       0.58      0.71      0.64        31\n",
            "\n",
            "    accuracy                           0.60        62\n",
            "   macro avg       0.60      0.60      0.59        62\n",
            "weighted avg       0.60      0.60      0.59        62\n",
            "\n",
            "Average F1 score: 0.5967741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNr3MNR1xNvB"
      },
      "source": [
        "#BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n-es6uZ-q1Q"
      },
      "source": [
        "params_bagging = {\n",
        "    'base_estimator': [SVC(C=1, class_weight='balanced', gamma=0.01), DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_leaf=5, min_samples_split=7), GaussianNB()],\n",
        "    'max_samples': [1, 3, 5, 10],\n",
        "}"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0gSN2gvxOsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dced5d36-a2b6-439a-f1e3-33903b4f4c34"
      },
      "source": [
        "clf = GridSearchCV(BaggingClassifier(), params_bagging, scoring='f1')\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "clf.best_params_"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=7, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=5, min_samples_split=7,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best'), 'max_samples': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKl26qs3yJyt",
        "outputId": "e2cd2cbd-7b43-46d9-d38a-3708809625b1"
      },
      "source": [
        "model = BaggingClassifier(\r\n",
        "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\r\n",
        "                        max_depth=7, max_features=None, max_leaf_nodes=None,\r\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
        "                        min_samples_leaf=5, min_samples_split=7,\r\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\r\n",
        "                        random_state=None, splitter='best'),\r\n",
        "                       max_samples=1\r\n",
        "                       )\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_bagging = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_bagging)}\\nAverage F1 score: {f1_score(y_test, y_pred_bagging, average=\"micro\")}')"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BaggingClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90       144\n",
            "           1       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.82       175\n",
            "   macro avg       0.41      0.50      0.45       175\n",
            "weighted avg       0.68      0.82      0.74       175\n",
            "\n",
            "Average F1 score: 0.8228571428571428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywUNg7ZO_S76",
        "outputId": "ca99fcfe-2261-4bff-c309-db1901d86f2a"
      },
      "source": [
        "clf = GridSearchCV(BaggingClassifier(), params_bagging, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=7, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=5, min_samples_split=7,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best'), 'max_samples': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsniPLTz_bey",
        "outputId": "09d3ca86-ebcf-4a08-b7c3-8dfc0c58a972"
      },
      "source": [
        "model = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                        max_depth=7, max_features=None, max_leaf_nodes=None,\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                        min_samples_leaf=5, min_samples_split=7,\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                        random_state=None, splitter='best'),\n",
        "                       max_samples=5\n",
        "                       )\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_bagging_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_bagging_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_bagging_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BaggingClassifier UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       145\n",
            "           1       0.50      1.00      0.67       144\n",
            "\n",
            "    accuracy                           0.50       289\n",
            "   macro avg       0.25      0.50      0.33       289\n",
            "weighted avg       0.25      0.50      0.33       289\n",
            "\n",
            "Average F1 score: 0.4982698961937716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKMtxUb4_t4U",
        "outputId": "0d819990-c7c8-45e5-d3af-a23637968378"
      },
      "source": [
        "clf = GridSearchCV(BaggingClassifier(), params_bagging, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Invalid input - all samples with positive weights have the same label.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=7, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=5, min_samples_split=7,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best'), 'max_samples': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oVHYWQH_2Zn",
        "outputId": "3678a0f4-66b6-4ae6-bf53-e1ce0eaa0073"
      },
      "source": [
        "model = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                        max_depth=7, max_features=None, max_leaf_nodes=None,\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                        min_samples_leaf=5, min_samples_split=7,\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                        random_state=None, splitter='best'),\n",
        "                       max_samples=3\n",
        "                       )\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_bagging_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_bagging_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_bagging_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BaggingClassifier UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        31\n",
            "           1       0.50      1.00      0.67        31\n",
            "\n",
            "    accuracy                           0.50        62\n",
            "   macro avg       0.25      0.50      0.33        62\n",
            "weighted avg       0.25      0.50      0.33        62\n",
            "\n",
            "Average F1 score: 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Gs59Nay9dZ"
      },
      "source": [
        "#AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ8JXni-AGl1"
      },
      "source": [
        "params_boosting = {\n",
        "    'base_estimator': [SVC(), DecisionTreeClassifier(), KNeighborsClassifier(), GaussianNB()],\n",
        "    'algorithm': ['SAMME', 'SAMME.R'],\n",
        "}"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKkdipZIy-d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedfd6ad-0a15-4a97-cc34-8a495a0d9ab2"
      },
      "source": [
        "clf = GridSearchCV(AdaBoostClassifier(random_state=42), params_boosting, scoring='f1')\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "clf.best_params_"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'SAMME',\n",
              " 'base_estimator': GaussianNB(priors=None, var_smoothing=1e-09)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agtwugVWznCR",
        "outputId": "b03beb90-9eb6-49e0-c40d-bba41e7a5973"
      },
      "source": [
        "model = AdaBoostClassifier(base_estimator=GaussianNB(priors=None, var_smoothing=1e-09),\r\n",
        "                        algorithm='SAMME')\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_boosting = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_boosting)}\\nAverage F1 score: {f1_score(y_test, y_pred_boosting, average=\"micro\")}')"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       144\n",
            "           1       0.67      0.32      0.43        31\n",
            "\n",
            "    accuracy                           0.85       175\n",
            "   macro avg       0.77      0.64      0.67       175\n",
            "weighted avg       0.83      0.85      0.83       175\n",
            "\n",
            "Average F1 score: 0.8514285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcVLtf0cA1gm",
        "outputId": "4147ccff-7f07-454d-e4bc-63436ea1236e"
      },
      "source": [
        "clf = GridSearchCV(AdaBoostClassifier(random_state=42), params_boosting, scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'SAMME',\n",
              " 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXFs3wW4AyKr",
        "outputId": "3c348de0-0de8-4bb7-afbc-27c0c4d31ac5"
      },
      "source": [
        "model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                        min_samples_leaf=1, min_samples_split=2,\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                        random_state=None, splitter='best'),\n",
        "                        algorithm='SAMME')\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_boosting_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_boosting_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_boosting_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.88      0.92       145\n",
            "           1       0.89      0.98      0.93       144\n",
            "\n",
            "    accuracy                           0.93       289\n",
            "   macro avg       0.93      0.93      0.93       289\n",
            "weighted avg       0.93      0.93      0.93       289\n",
            "\n",
            "Average F1 score: 0.9273356401384083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNjIQTC6BQ4E",
        "outputId": "23d192ae-fcca-4edd-ce2c-5586f66eec3c"
      },
      "source": [
        "clf = GridSearchCV(AdaBoostClassifier(random_state=42), params_boosting, scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
            "Please change the base estimator or set algorithm='SAMME' instead.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'SAMME',\n",
              " 'base_estimator': GaussianNB(priors=None, var_smoothing=1e-09)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlC9ZpBGBcwv",
        "outputId": "3981d5c0-df80-40c5-ab75-c0984033dc4e"
      },
      "source": [
        "model = AdaBoostClassifier(base_estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
        "                        algorithm='SAMME')\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_boosting_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_boosting_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_boosting_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.61      0.64        31\n",
            "           1       0.65      0.71      0.68        31\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.66      0.66      0.66        62\n",
            "weighted avg       0.66      0.66      0.66        62\n",
            "\n",
            "Average F1 score: 0.6612903225806451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fPkXkiLz9sx"
      },
      "source": [
        "#RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htkmsrayB1v4"
      },
      "source": [
        "params_forest = {\n",
        "    # 'n_estimators': [100, 200, 500],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, 15],\n",
        "    'min_samples_split': [2, 4, 6, 9],\n",
        "    'min_samples_leaf': [2, 3, 4, 5],\n",
        "    'max_features': ['auto', None]\n",
        "}"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXpv0c07z-sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da147fa-3625-4cba-cdef-ced3bfcbcce0"
      },
      "source": [
        "clf = GridSearchCV(RandomForestClassifier(random_state=42), params_forest,scoring='f1')\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "clf.best_params_"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 15,\n",
              " 'max_features': None,\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NgN4_rO3N2V",
        "outputId": "e00af8b3-e967-405e-98d8-add4af189b4c"
      },
      "source": [
        "model = RandomForestClassifier(criterion='gini', max_depth=15, max_features=None, min_samples_leaf=2, min_samples_split=2)\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_forest = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_forest)}\\nAverage F1 score: {f1_score(y_test, y_pred_forest, average=\"micro\")}')"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93       144\n",
            "           1       0.90      0.29      0.44        31\n",
            "\n",
            "    accuracy                           0.87       175\n",
            "   macro avg       0.88      0.64      0.68       175\n",
            "weighted avg       0.87      0.87      0.84       175\n",
            "\n",
            "Average F1 score: 0.8685714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfJDtU8D16g",
        "outputId": "b6e1280a-1f69-45ac-e5ce-700c679f22d0"
      },
      "source": [
        "clf = GridSearchCV(RandomForestClassifier(random_state=42), params_forest,scoring='f1')\n",
        "clf.fit(X_train_upsampled, y_train_upsampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrIOMcSZBVtt",
        "outputId": "3c645ea5-fd9f-45a5-81c7-84f627d5e5a2"
      },
      "source": [
        "model = RandomForestClassifier(criterion='entropy', max_depth=15, max_features='auto', min_samples_leaf=2, min_samples_split=2)\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_forest_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED \\n{classification_report(y_test_upsampled, y_pred_forest_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_forest_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier UPSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       145\n",
            "           1       0.99      0.95      0.97       144\n",
            "\n",
            "    accuracy                           0.97       289\n",
            "   macro avg       0.97      0.97      0.97       289\n",
            "weighted avg       0.97      0.97      0.97       289\n",
            "\n",
            "Average F1 score: 0.9688581314878892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B8zdZfAFY6t",
        "outputId": "220c3068-8371-4c0c-84ab-f67ab7586d7e"
      },
      "source": [
        "clf = GridSearchCV(RandomForestClassifier(random_state=42), params_forest,scoring='f1')\n",
        "clf.fit(X_train_undersampled, y_train_undersampled)\n",
        "clf.best_params_"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 5,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Bq4MDOFQOg",
        "outputId": "28dfa860-51ad-41f9-8413-724b61e93f9c"
      },
      "source": [
        "model = RandomForestClassifier(criterion='entropy', max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=6)\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_forest_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_forest_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_forest_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.65      0.67        31\n",
            "           1       0.67      0.71      0.69        31\n",
            "\n",
            "    accuracy                           0.68        62\n",
            "   macro avg       0.68      0.68      0.68        62\n",
            "weighted avg       0.68      0.68      0.68        62\n",
            "\n",
            "Average F1 score: 0.6774193548387096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sZ5KwTnEPKa"
      },
      "source": [
        "# VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnBraMU6Gm1y",
        "outputId": "511864a4-5bde-46c2-872a-f96ea3cfc2e0"
      },
      "source": [
        "model = VotingClassifier(estimators=[('forest', RandomForestClassifier(criterion='gini', max_depth=15, max_features=None, min_samples_leaf=2, min_samples_split=2)),\r\n",
        "                                      ('boosting', AdaBoostClassifier(base_estimator=GaussianNB(priors=None, var_smoothing=1e-09))),\r\n",
        "                                      ('svm', SVC(C=1, class_weight='balanced', gamma=0.000001)), \r\n",
        "                                      ('gaussian', GaussianNB())], voting='hard')\r\n",
        "model.fit(X_train, y_train)\r\n",
        "y_pred_voting = model.predict(X_test)\r\n",
        "print(f'{model.__class__.__name__}\\n{classification_report(y_test, y_pred_voting)}\\nAverage F1 score: {f1_score(y_test, y_pred_voting, average=\"micro\")}')"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.98      0.91       144\n",
            "           1       0.62      0.16      0.26        31\n",
            "\n",
            "    accuracy                           0.83       175\n",
            "   macro avg       0.73      0.57      0.58       175\n",
            "weighted avg       0.81      0.83      0.79       175\n",
            "\n",
            "Average F1 score: 0.8342857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwi7jYyzJNGX",
        "outputId": "0dd83990-3e13-44c5-b277-7aaad82c85f4"
      },
      "source": [
        "model = VotingClassifier(estimators=[('forest', RandomForestClassifier(criterion='entropy', max_depth=15, max_features='auto', min_samples_leaf=2, min_samples_split=2)),\n",
        "                                      ('boosting', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                        min_samples_leaf=1, min_samples_split=2,\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                        random_state=None, splitter='best'),\n",
        "                        algorithm='SAMME')),\n",
        "                        ('svm', SVC(C=1, class_weight=None, gamma=0.0001)), ('gaussian', GaussianNB())], voting='hard')\n",
        "model.fit(X_train_upsampled, y_train_upsampled)\n",
        "y_pred_voting_upsampled = model.predict(X_test_upsampled)\n",
        "print(f'{model.__class__.__name__} UPSAMPLED\\n{classification_report(y_test_upsampled, y_pred_voting_upsampled)}\\nAverage F1 score: {f1_score(y_test_upsampled, y_pred_voting_upsampled, average=\"micro\")}')"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier UPSAMPLED\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       145\n",
            "           1       0.97      0.94      0.96       144\n",
            "\n",
            "    accuracy                           0.96       289\n",
            "   macro avg       0.96      0.96      0.96       289\n",
            "weighted avg       0.96      0.96      0.96       289\n",
            "\n",
            "Average F1 score: 0.9584775086505191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULu8F5tnJwB-",
        "outputId": "beece24a-efa4-4f93-ba2d-576c8022a197"
      },
      "source": [
        "model = VotingClassifier(estimators=[('forest', RandomForestClassifier(criterion='entropy', max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=6)),\n",
        "                                      ('boosting', AdaBoostClassifier(base_estimator=GaussianNB(priors=None, var_smoothing=1e-09))),\n",
        "                        ('svm', SVC(C=1, class_weight=None, gamma=0.000001)), ('gaussian', GaussianNB())], voting='hard')\n",
        "model.fit(X_train_undersampled, y_train_undersampled)\n",
        "y_pred_voting_undersampled = model.predict(X_test_undersampled)\n",
        "print(f'{model.__class__.__name__} UNDERSAMPLED \\n{classification_report(y_test_undersampled, y_pred_voting_undersampled)}\\nAverage F1 score: {f1_score(y_test_undersampled, y_pred_voting_undersampled, average=\"micro\")}')"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier UNDERSAMPLED \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.81      0.75        31\n",
            "           1       0.77      0.65      0.70        31\n",
            "\n",
            "    accuracy                           0.73        62\n",
            "   macro avg       0.73      0.73      0.72        62\n",
            "weighted avg       0.73      0.73      0.72        62\n",
            "\n",
            "Average F1 score: 0.7258064516129032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZTCDPrH40Oy",
        "outputId": "f6e9ba5c-0cbf-42d5-c6b7-79e6f057bd1d"
      },
      "source": [
        "# Zestawienie wyników wszystkich przebadanych klasyfikatorów i wyłonienie zwycięzcy\r\n",
        "y_preds = [y_pred_lr, y_pred_knn, y_pred_svc, y_pred_gnb, y_pred_mnb, y_pred_tree, y_pred_bagging, y_pred_boosting, y_pred_forest, y_pred_voting]\r\n",
        "y_preds_upsampled = [y_pred_lr_upsampled, y_pred_knn_upsampled, y_pred_svc_upsampled, y_pred_gnb_upsampled, y_pred_mnb_upsampled, y_pred_tree_upsampled, y_pred_bagging_upsampled, y_pred_boosting_upsampled, y_pred_forest_upsampled, y_pred_voting_upsampled]\r\n",
        "y_preds_undersampled = [y_pred_lr_undersampled, y_pred_knn_undersampled, y_pred_svc_undersampled, y_pred_gnb_undersampled, y_pred_mnb_undersampled, y_pred_tree_undersampled, y_pred_bagging_undersampled, y_pred_boosting_undersampled, y_pred_forest_undersampled, y_pred_voting_undersampled]\r\n",
        "f1_scores = []\r\n",
        "precision_scores = []\r\n",
        "recall_scores = []\r\n",
        "for y_pred in y_preds:\r\n",
        "  f1_scores.append(f1_score(y_test, y_pred, average=\"micro\"))\r\n",
        "  precision_scores.append(precision_score(y_test, y_pred, average=\"micro\"))\r\n",
        "  recall_scores.append(recall_score(y_test, y_pred, average=\"micro\"))\r\n",
        "  print(f'F1 score: {f1_score(y_test, y_pred, average=\"micro\")},     Precision: {precision_score(y_test, y_pred, average=\"micro\")},       Recall: {recall_score(y_test, y_pred, average=\"micro\")}')\r\n",
        "print(f'\\n-----------UPSAMPLED-----------------------------------')\r\n",
        "f1_scores_upsampled = []\r\n",
        "precision_scores_upsampled = []\r\n",
        "recall_scores_upsampled = []\r\n",
        "for y_pred in y_preds_upsampled:\r\n",
        "  f1_scores_upsampled.append(f1_score(y_test_upsampled, y_pred, average=\"micro\"))\r\n",
        "  precision_scores_upsampled.append(precision_score(y_test_upsampled, y_pred, average=\"micro\"))\r\n",
        "  recall_scores_upsampled.append(recall_score(y_test_upsampled, y_pred, average=\"micro\"))\r\n",
        "  print(f'F1 score: {f1_score(y_test_upsampled, y_pred, average=\"micro\")},     Precision: {precision_score(y_test_upsampled, y_pred, average=\"micro\")},       Recall: {recall_score(y_test_upsampled, y_pred, average=\"micro\")}')\r\n",
        "print(f'\\n-----------UNDERSAMPLED-----------------------------------')\r\n",
        "f1_scores_undersampled = []\r\n",
        "precision_scores_undersampled = []\r\n",
        "recall_scores_undersampled = []\r\n",
        "for y_pred in y_preds_undersampled:\r\n",
        "  f1_scores_undersampled.append(f1_score(y_test_undersampled, y_pred, average=\"micro\"))\r\n",
        "  precision_scores_undersampled.append(precision_score(y_test_undersampled, y_pred, average=\"micro\"))\r\n",
        "  recall_scores_undersampled.append(recall_score(y_test_undersampled, y_pred, average=\"micro\"))\r\n",
        "  print(f'F1 score: {f1_score(y_test_undersampled, y_pred, average=\"micro\")},     Precision: {precision_score(y_test_undersampled, y_pred, average=\"micro\")},       Recall: {recall_score(y_test_undersampled, y_pred, average=\"micro\")}')"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.8399999999999999,     Precision: 0.84,       Recall: 0.84\n",
            "F1 score: 0.7885714285714286,     Precision: 0.7885714285714286,       Recall: 0.7885714285714286\n",
            "F1 score: 0.6628571428571428,     Precision: 0.6628571428571428,       Recall: 0.6628571428571428\n",
            "F1 score: 0.7542857142857143,     Precision: 0.7542857142857143,       Recall: 0.7542857142857143\n",
            "F1 score: 0.5371428571428571,     Precision: 0.5371428571428571,       Recall: 0.5371428571428571\n",
            "F1 score: 0.8114285714285714,     Precision: 0.8114285714285714,       Recall: 0.8114285714285714\n",
            "F1 score: 0.8228571428571428,     Precision: 0.8228571428571428,       Recall: 0.8228571428571428\n",
            "F1 score: 0.8514285714285714,     Precision: 0.8514285714285714,       Recall: 0.8514285714285714\n",
            "F1 score: 0.8685714285714285,     Precision: 0.8685714285714285,       Recall: 0.8685714285714285\n",
            "F1 score: 0.8342857142857143,     Precision: 0.8342857142857143,       Recall: 0.8342857142857143\n",
            "\n",
            "-----------UPSAMPLED-----------------------------------\n",
            "F1 score: 0.7820069204152249,     Precision: 0.7820069204152249,       Recall: 0.7820069204152249\n",
            "F1 score: 0.8996539792387543,     Precision: 0.8996539792387543,       Recall: 0.8996539792387543\n",
            "F1 score: 0.9896193771626297,     Precision: 0.9896193771626297,       Recall: 0.9896193771626297\n",
            "F1 score: 0.671280276816609,     Precision: 0.671280276816609,       Recall: 0.671280276816609\n",
            "F1 score: 0.5294117647058824,     Precision: 0.5294117647058824,       Recall: 0.5294117647058824\n",
            "F1 score: 0.9273356401384083,     Precision: 0.9273356401384083,       Recall: 0.9273356401384083\n",
            "F1 score: 0.4982698961937716,     Precision: 0.4982698961937716,       Recall: 0.4982698961937716\n",
            "F1 score: 0.9273356401384083,     Precision: 0.9273356401384083,       Recall: 0.9273356401384083\n",
            "F1 score: 0.9688581314878892,     Precision: 0.9688581314878892,       Recall: 0.9688581314878892\n",
            "F1 score: 0.9584775086505191,     Precision: 0.9584775086505191,       Recall: 0.9584775086505191\n",
            "\n",
            "-----------UNDERSAMPLED-----------------------------------\n",
            "F1 score: 0.6612903225806451,     Precision: 0.6612903225806451,       Recall: 0.6612903225806451\n",
            "F1 score: 0.6290322580645161,     Precision: 0.6290322580645161,       Recall: 0.6290322580645161\n",
            "F1 score: 0.7096774193548389,     Precision: 0.7096774193548387,       Recall: 0.7096774193548387\n",
            "F1 score: 0.6451612903225806,     Precision: 0.6451612903225806,       Recall: 0.6451612903225806\n",
            "F1 score: 0.5967741935483871,     Precision: 0.5967741935483871,       Recall: 0.5967741935483871\n",
            "F1 score: 0.6290322580645161,     Precision: 0.6290322580645161,       Recall: 0.6290322580645161\n",
            "F1 score: 0.5,     Precision: 0.5,       Recall: 0.5\n",
            "F1 score: 0.6612903225806451,     Precision: 0.6612903225806451,       Recall: 0.6612903225806451\n",
            "F1 score: 0.6774193548387096,     Precision: 0.6774193548387096,       Recall: 0.6774193548387096\n",
            "F1 score: 0.7258064516129032,     Precision: 0.7258064516129032,       Recall: 0.7258064516129032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2DfrviRL97N"
      },
      "source": [
        "W oryginalnym zbiorze najlepszy okazała się model 1. RandomForest, 2. AdaBoost\n",
        "OVERSAMPLING: 1.SVC, 2. RandomForest\n",
        "UNDERSAMPLING: 1. Voting, 2. SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbpQnATWC1Rz"
      },
      "source": [
        "# Zestawienie i zapis wszystkich modeli z najlepszymi parametrami\r\n",
        "clf_lr = LogisticRegression(C=1, max_iter=100, solver='newton-cg',random_state=42)\r\n",
        "clf_knn = KNeighborsClassifier(algorithm='auto', n_neighbors=3, p=2)\r\n",
        "clf_svc = SVC(C=100, class_weight=None, gamma=0.1,random_state=42)\r\n",
        "clf_tree = DecisionTreeClassifier(criterion='gini', max_depth=9, min_samples_leaf=1, min_samples_split=2, random_state=42)\r\n",
        "clf_gnb = GaussianNB()\r\n",
        "clf_mnb = MultinomialNB()\r\n",
        "clf_bagging = BaggingClassifier(\r\n",
        "    base_estimator=SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\r\n",
        "                       decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\r\n",
        "                       max_iter=-1, probability=False, random_state=None, shrinking=True,\r\n",
        "                       tol=0.001, verbose=False),\r\n",
        "                       max_samples=10\r\n",
        "                       )\r\n",
        "clf_boosting = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\r\n",
        "                        max_depth=9, max_features=None, max_leaf_nodes=None,\r\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
        "                        min_samples_leaf=1, min_samples_split=2,\r\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\r\n",
        "                        random_state=None, splitter='best'),\r\n",
        "                        algorithm='SAMME')\r\n",
        "clf_forest = RandomForestClassifier(criterion='entropy', max_depth=15, max_features=None, min_samples_leaf=2, min_samples_split=2, random_state=42)\r\n",
        "clf_voting = VotingClassifier(estimators=[('forest', RandomForestClassifier(criterion='entropy', max_depth=15, max_features=None, min_samples_leaf=2, min_samples_split=2)),\r\n",
        "                                      ('boosting', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\r\n",
        "                        max_depth=9, max_features=None, max_leaf_nodes=None,\r\n",
        "                        min_impurity_decrease=0.0, min_impurity_split=None,\r\n",
        "                        min_samples_leaf=1, min_samples_split=2,\r\n",
        "                        min_weight_fraction_leaf=0.0, presort='deprecated',\r\n",
        "                        random_state=None, splitter='best'),\r\n",
        "                        algorithm='SAMME')),\r\n",
        "                        ('svm', SVC(C=100, class_weight=None, gamma=0.1,random_state=42))], voting='hard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQJGPxfnKkgw"
      },
      "source": [
        "# Weryfikacja skuteczności modeli na danych znormalizowanych, standaryzowanych i zdyskretyzowanych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El8v2JMyPD_q"
      },
      "source": [
        "preprocesser = [None, Normalizer(), StandardScaler(), MinMaxScaler(), KBinsDiscretizer(n_bins=10, strategy='uniform')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL8xSAo9McVw"
      },
      "source": [
        "# Normalizacja\r\n",
        "X_normalized = preprocesser[1].fit_transform(X)\r\n",
        "X_normalized_upsampled = preprocesser[1].fit_transform(X_upsampled)\r\n",
        "X_normalized_undersampled = preprocesser[1].fit_transform(X_undersampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYaVWR9uM29q"
      },
      "source": [
        "# Standaryzacja\r\n",
        "X_standarized = preprocesser[2].fit_transform(X)\r\n",
        "X_standarized_upsampled = preprocesser[2].fit_transform(X_upsampled)\r\n",
        "X_standarized_undersampled = preprocesser[2].fit_transform(X_undersampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU6S2qQNU-_4"
      },
      "source": [
        "# MinMax Standaryzacja\r\n",
        "X_minmax_standarized = preprocesser[3].fit_transform(X)\r\n",
        "X_minmax_standarized_upsampled = preprocesser[3].fit_transform(X_upsampled)\r\n",
        "X_minmax_standarized_undersampled = preprocesser[3].fit_transform(X_undersampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2zfiWcFcNPU"
      },
      "source": [
        "# Dyskretyzacja\r\n",
        "X_bins = preprocesser[4].fit_transform(X)\r\n",
        "X_bins_upsampled = preprocesser[4].fit_transform(X_upsampled)\r\n",
        "X_bins_undersampled = preprocesser[4].fit_transform(X_undersampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fqnlvzILgGo",
        "outputId": "7186573a-6331-415a-ea44-59be810d33f4"
      },
      "source": [
        "# Kroswalidacja na danych znormalizowanych - wyniki dla wszystkich modeli\r\n",
        "for clf in (clf_lr, clf_knn, clf_svc, clf_tree, clf_gnb, clf_mnb, clf_bagging, clf_boosting, clf_forest, clf_voting):\r\n",
        "  predicted, true = [], []\r\n",
        "  for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_normalized, y):\r\n",
        "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf.fit(X=X_train, y=y_train)\r\n",
        "    predicted.extend(clf.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "  print(f\"{clf.__class__.__name__}: Average F1 score:{f1_score(true, predicted, average='micro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression: Average F1 score:0.7304768486523843\n",
            "KNeighborsClassifier: Average F1 score:0.7598479612992398\n",
            "SVC: Average F1 score:0.756046993780235\n",
            "DecisionTreeClassifier: Average F1 score:0.8051140290255702\n",
            "GaussianNB: Average F1 score:0.5566689702833448\n",
            "MultinomialNB: Average F1 score:0.7277125086385625\n",
            "BaggingClassifier: Average F1 score:0.7062888735314443\n",
            "AdaBoostClassifier: Average F1 score:0.861782999308915\n",
            "RandomForestClassifier: Average F1 score:0.849689011748445\n",
            "VotingClassifier: Average F1 score:0.8541810642709053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aD422h_SARi",
        "outputId": "0bbc8926-4cc2-4d4b-b157-0caa28989090"
      },
      "source": [
        "# Kroswalidacja na danych standaryzowanych - wyniki dla wszystkich modeli\r\n",
        "for clf in (clf_lr, clf_knn, clf_svc, clf_tree, clf_gnb, clf_bagging, clf_boosting, clf_forest, clf_voting):\r\n",
        "  predicted, true = [], []\r\n",
        "  for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_standarized, y):\r\n",
        "    X_train, X_test = X_standarized[train_index], X_standarized[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf.fit(X=X_train, y=y_train)\r\n",
        "    predicted.extend(clf.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "  print(f\"{clf.__class__.__name__}: Average F1 score:{f1_score(true, predicted, average='micro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression: Average F1 score:0.7639944713199723\n",
            "KNeighborsClassifier: Average F1 score:0.7176917760884589\n",
            "SVC: Average F1 score:0.7850725639253628\n",
            "DecisionTreeClassifier: Average F1 score:0.8182446440912232\n",
            "GaussianNB: Average F1 score:0.6651693158258466\n",
            "BaggingClassifier: Average F1 score:0.5269523151347616\n",
            "AdaBoostClassifier: Average F1 score:0.8631651693158259\n",
            "RandomForestClassifier: Average F1 score:0.8514167242570836\n",
            "VotingClassifier: Average F1 score:0.8610919143054596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnppUEebU3W9",
        "outputId": "aab23d47-4083-4f80-cd74-4239d608d2c3"
      },
      "source": [
        "# Kroswalidacja na danych standaryzowanych MinMax- wyniki dla wszystkich modeli bez mnb\r\n",
        "for clf in (clf_lr, clf_knn, clf_svc, clf_tree, clf_gnb, clf_bagging, clf_boosting, clf_forest, clf_voting):\r\n",
        "  predicted, true = [], []\r\n",
        "  for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_minmax_standarized, y):\r\n",
        "    X_train, X_test = X_minmax_standarized[train_index], X_minmax_standarized[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf.fit(X=X_train, y=y_train)\r\n",
        "    predicted.extend(clf.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "  print(f\"{clf.__class__.__name__}: Average F1 score:{f1_score(true, predicted, average='micro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression: Average F1 score:0.7639944713199723\n",
            "KNeighborsClassifier: Average F1 score:0.7100898410504493\n",
            "SVC: Average F1 score:0.8296475466482377\n",
            "DecisionTreeClassifier: Average F1 score:0.8165169315825846\n",
            "GaussianNB: Average F1 score:0.6651693158258466\n",
            "BaggingClassifier: Average F1 score:0.5836212854181064\n",
            "AdaBoostClassifier: Average F1 score:0.8683483068417416\n",
            "RandomForestClassifier: Average F1 score:0.8507256392536282\n",
            "VotingClassifier: Average F1 score:0.8548721492743607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agJVNl2Fc2Fh",
        "outputId": "9a8eb08d-6318-4e3c-b78c-acab58c528da"
      },
      "source": [
        "# Kroswalidacja na danych zdyskretyzowanych - wyniki dla wszystkich modeli bez gnb\r\n",
        "for clf in (clf_lr, clf_knn, clf_svc, clf_tree, clf_bagging, clf_boosting, clf_forest, clf_voting):\r\n",
        "  predicted, true = [], []\r\n",
        "  for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_bins, y):\r\n",
        "    X_train, X_test = X_bins[train_index], X_bins[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf.fit(X=X_train, y=y_train)\r\n",
        "    predicted.extend(clf.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "  print(f\"{clf.__class__.__name__}: Average F1 score:{f1_score(true, predicted, average='micro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression: Average F1 score:0.7843814789219073\n",
            "KNeighborsClassifier: Average F1 score:0.7194194885970974\n",
            "SVC: Average F1 score:0.7909467864547339\n",
            "DecisionTreeClassifier: Average F1 score:0.8113337940566689\n",
            "BaggingClassifier: Average F1 score:0.5093296475466482\n",
            "AdaBoostClassifier: Average F1 score:0.8441603317208016\n",
            "RandomForestClassifier: Average F1 score:0.848652384243262\n",
            "VotingClassifier: Average F1 score:0.8514167242570836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ0ieit9W70W"
      },
      "source": [
        "Najlepszy rezultat spośród wszystkich modeli (0.8683483068417416) daje AdaBoostClassifier na danych przetransformowanych MinMaxScaler'em.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PZDgTm7hspi",
        "outputId": "eb1d8315-e4a2-4172-8d06-beefadf602d7"
      },
      "source": [
        "# Sprawdzenie najlepszego modelu na różnych wariantach kroswalidacji na danych standaryzowanych MinMax\r\n",
        "n_splits = [3, 5, 10, 20, 30, 50, 70, 100, 130]\r\n",
        "f1_scores = []\r\n",
        "for n_split in n_splits:\r\n",
        "  print(f'StratifiedKFold n_splits= {n_split}')\r\n",
        "  predicted, true = [], []\r\n",
        "  for train_index, test_index in StratifiedKFold(n_splits=n_split, shuffle=True, random_state=42).split(X_minmax_standarized, y):\r\n",
        "    X_train, X_test = X_minmax_standarized[train_index], X_minmax_standarized[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf_boosting.fit(X=X_train, y=y_train)  #AdaBoostClassifier\r\n",
        "    predicted.extend(clf_boosting.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "  print(f\"Average F1 score:{f1_score(true, predicted, average='micro')}\")\r\n",
        "  f1_scores.append(f1_score(true, predicted, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold n_splits= 3\n",
            "Average F1 score:0.8427781617138909\n",
            "StratifiedKFold n_splits= 5\n",
            "Average F1 score:0.8483068417415343\n",
            "StratifiedKFold n_splits= 10\n",
            "Average F1 score:0.8680027643400138\n",
            "StratifiedKFold n_splits= 20\n",
            "Average F1 score:0.8707671043538355\n",
            "StratifiedKFold n_splits= 30\n",
            "Average F1 score:0.869039391845197\n",
            "StratifiedKFold n_splits= 50\n",
            "Average F1 score:0.8742225293711127\n",
            "StratifiedKFold n_splits= 70\n",
            "Average F1 score:0.8762957843814789\n",
            "StratifiedKFold n_splits= 100\n",
            "Average F1 score:0.8752591568762957\n",
            "StratifiedKFold n_splits= 130\n",
            "Average F1 score:0.8735314443676572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "J0wyHqCdohKM",
        "outputId": "28abfbac-5b7c-4a4b-d105-434ae2c057ae"
      },
      "source": [
        "plt.figure(figsize=(20, 10))\r\n",
        "plt.plot(n_splits, f1_scores, label=\"F1_scores vs n_splits\")\r\n",
        "plt.xlabel(\"n_splitse\")\r\n",
        "# plt.xticks(range(1, 11, 1))\r\n",
        "plt.ylabel(\"F1_scores\")\r\n",
        "plt.legend(loc='best')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XWHC4pft_Qi"
      },
      "source": [
        "Najlepszy wynik uzyskujemy dla korswalidacji podzielonej na n_splits=70 przy AdaBoostClassifier na danych standaryzowanych MinMaxScaler'em. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "scWR5SfjucJE",
        "outputId": "46cf127b-efcd-46e2-abed-6341d8d5c446"
      },
      "source": [
        "for train_index, test_index in StratifiedKFold(n_splits=70, shuffle=True, random_state=42).split(X_minmax_standarized, y):\r\n",
        "    X_train, X_test = X_minmax_standarized[train_index], X_minmax_standarized[test_index]\r\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n",
        "    clf_boosting.fit(X=X_train, y=y_train)  #AdaBoostClassifier\r\n",
        "    predicted.extend(clf_boosting.predict(X_test))\r\n",
        "    true.extend(y_test)\r\n",
        "print(f'{clf_boosting.__class__.__name__}\\n{classification_report(true, predicted)}\\nAverage F1 score: {f1_score(true, predicted, average=\"micro\")}')\r\n",
        "cm = confusion_matrix(true, predicted)\r\n",
        "sns.heatmap(cm, annot=True, fmt='d')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.87      3377\n",
            "           1       0.86      0.90      0.88      3377\n",
            "\n",
            "    accuracy                           0.88      6754\n",
            "   macro avg       0.88      0.88      0.88      6754\n",
            "weighted avg       0.88      0.88      0.88      6754\n",
            "\n",
            "Average F1 score: 0.8759253775540421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuS1H--1wZC6"
      },
      "source": [
        "#Ostateczna predykcja na zbiorze testowym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "XFvFPr3fwBJq",
        "outputId": "373a7231-1676-4b40-c944-a964a14ce011"
      },
      "source": [
        "data_final_test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>100142</td>\n",
              "      <td>35.0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>208.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Healthcare Representative</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>4148.0</td>\n",
              "      <td>12250.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>100143</td>\n",
              "      <td>41.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>582.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Manufacturing Director</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>13570.0</td>\n",
              "      <td>5640.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>100144</td>\n",
              "      <td>42.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1396.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Research Director</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>13348.0</td>\n",
              "      <td>14842.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>No</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>100145</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>621.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Healthcare Representative</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Married</td>\n",
              "      <td>7978.0</td>\n",
              "      <td>14075.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>100146</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>381.0</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Single</td>\n",
              "      <td>3708.0</td>\n",
              "      <td>2104.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      EmployeeNumber   Age  ... YearsWithCurrManager  Attrition\n",
              "1465          100142  35.0  ...                  9.0        NaN\n",
              "1466          100143  41.0  ...                 10.0        NaN\n",
              "1467          100144  42.0  ...                  7.0        NaN\n",
              "1468          100145  44.0  ...                  5.0        NaN\n",
              "1469          100146  44.0  ...                  4.0        NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn57AK1LwrtV"
      },
      "source": [
        "# Przygotowanie danych testowych\r\n",
        "\r\n",
        "# Zamiana w etykietowwanych featurach etykiet klasyfikujących na one hot vector\r\n",
        "data_final_test_dummies = pd.get_dummies(data_final_test, columns=['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBSaCrL8yJmH"
      },
      "source": [
        "# Przypisanie wartości do danych testowych\r\n",
        "X_final_test = data_final_test_dummies.loc[:,data_final_test_dummies.columns != 'Attrition']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-bZNyoIzTMW"
      },
      "source": [
        "# Finalna predykcja\r\n",
        "y_final_predict = clf_boosting.predict(X_final_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amyKJXBTz14g",
        "outputId": "5116285e-85f0-4487-fbbf-f228835a5170"
      },
      "source": [
        "# Weryfiukacja predykcyjnych wartości\r\n",
        "pd.DataFrame(y_final_predict).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    147\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oS4eSB4wLr",
        "outputId": "19bf93db-8287-463c-dd84-365f4a8cf4ee"
      },
      "source": [
        "y_final_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlmAVtPC1kD-"
      },
      "source": [
        "# Nadpisanie predykcyjnych wartości za NaNy w zbiorze testowym\r\n",
        "data_final_test_dummies.Attrition = y_final_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "FU93WlnO2acY",
        "outputId": "c57679a4-7bed-44b1-808f-1ed4cb60e6c9"
      },
      "source": [
        "data_final_test_dummies.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>100142</td>\n",
              "      <td>35.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4148.0</td>\n",
              "      <td>12250.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>100143</td>\n",
              "      <td>41.0</td>\n",
              "      <td>582.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13570.0</td>\n",
              "      <td>5640.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>100144</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1396.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13348.0</td>\n",
              "      <td>14842.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>100145</td>\n",
              "      <td>44.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7978.0</td>\n",
              "      <td>14075.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>100146</td>\n",
              "      <td>44.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3708.0</td>\n",
              "      <td>2104.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      EmployeeNumber   Age  ...  OverTime_No  OverTime_Yes\n",
              "1465          100142  35.0  ...            1             0\n",
              "1466          100143  41.0  ...            1             0\n",
              "1467          100144  42.0  ...            1             0\n",
              "1468          100145  44.0  ...            1             0\n",
              "1469          100146  44.0  ...            1             0\n",
              "\n",
              "[5 rows x 53 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l91YIQdl6STB"
      },
      "source": [
        "output = pd.DataFrame(data_final_test_dummies, columns=['EmployeeNumber', 'Attrition'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNV8qmsrYjUU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2aebf5fa-c2fd-4034-e49c-d75869081646"
      },
      "source": [
        "output.tail(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>100097</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1421</th>\n",
              "      <td>100098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>100099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>100100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>100101</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>100102</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>100103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1427</th>\n",
              "      <td>100104</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1428</th>\n",
              "      <td>100105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1429</th>\n",
              "      <td>100106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>100107</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431</th>\n",
              "      <td>100108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1432</th>\n",
              "      <td>100109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>100110</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>100111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>100112</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>100113</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>100114</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>100115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>100116</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1440</th>\n",
              "      <td>100117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1441</th>\n",
              "      <td>100118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1442</th>\n",
              "      <td>100119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>100120</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1444</th>\n",
              "      <td>100121</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1445</th>\n",
              "      <td>100122</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>100123</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>100124</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>100125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1449</th>\n",
              "      <td>100126</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1450</th>\n",
              "      <td>100127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>100128</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>100129</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>100130</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>100131</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>100132</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>100133</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>100134</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>100135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>100136</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>100137</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>100138</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1462</th>\n",
              "      <td>100139</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>100140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1464</th>\n",
              "      <td>100141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>100142</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>100143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>100144</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>100145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>100146</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      EmployeeNumber  Attrition\n",
              "1420          100097          0\n",
              "1421          100098          0\n",
              "1422          100099          0\n",
              "1423          100100          0\n",
              "1424          100101          0\n",
              "1425          100102          0\n",
              "1426          100103          0\n",
              "1427          100104          0\n",
              "1428          100105          0\n",
              "1429          100106          0\n",
              "1430          100107          0\n",
              "1431          100108          0\n",
              "1432          100109          0\n",
              "1433          100110          0\n",
              "1434          100111          0\n",
              "1435          100112          0\n",
              "1436          100113          0\n",
              "1437          100114          0\n",
              "1438          100115          0\n",
              "1439          100116          0\n",
              "1440          100117          0\n",
              "1441          100118          0\n",
              "1442          100119          0\n",
              "1443          100120          0\n",
              "1444          100121          0\n",
              "1445          100122          0\n",
              "1446          100123          0\n",
              "1447          100124          0\n",
              "1448          100125          0\n",
              "1449          100126          0\n",
              "1450          100127          0\n",
              "1451          100128          0\n",
              "1452          100129          0\n",
              "1453          100130          0\n",
              "1454          100131          0\n",
              "1455          100132          0\n",
              "1456          100133          0\n",
              "1457          100134          0\n",
              "1458          100135          0\n",
              "1459          100136          0\n",
              "1460          100137          0\n",
              "1461          100138          0\n",
              "1462          100139          0\n",
              "1463          100140          0\n",
              "1464          100141          0\n",
              "1465          100142          0\n",
              "1466          100143          0\n",
              "1467          100144          0\n",
              "1468          100145          0\n",
              "1469          100146          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    }
  ]
}